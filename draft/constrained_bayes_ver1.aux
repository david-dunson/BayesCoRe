\relax 
\citation{boyd2004convex}
\citation{gelfand1992bayesian}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}}
\citation{khatri1977mises,hoff2009simulation}
\citation{gelfand1992bayesian}
\citation{lin2014monogp}
\citation{lin2016extrinsic}
\citation{neal2011mcmc}
\citation{pakman2014exact}
\citation{girolami2011riemann,byrne2013geodesic}
\@writefile{toc}{\contentsline {section}{\numberline {2}Extrinsic Bayes Methodology}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Intrinsic Bayes}{3}}
\newlabel{exact_prior1}{{1}{3}}
\newlabel{exact_prior2}{{2}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Extrinsic Prior}{4}}
\newlabel{extrinsic_prior}{{3}{4}}
\newlabel{smoothing}{{4}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Unnormalized densities for truncated normal $\No  _{(-\infty ,5)}(0,5^2)$ under exact intrinsic prior and approximating extrinsic prior. Inside $(-\infty ,5)$, the priors are the same up to a constant difference. The intrinsic prior abruptly drops to $0$ on the boundary, while the approximating ones drop continuously. Intrinsic prior based on first-order $v(\theta )$ drops faster than the one based on second order when $v(\theta )\in (0,1)$.\relax }}{5}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{truncated_normal}{{1}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Property of Extrinsic Prior}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Selection of Kernel Hyper-Parameters}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Control of Constraint Relaxation}{6}}
\citation{hoffman2014no}
\citation{hoffman2014no}
\citation{zhang2012continuous}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6}Hamiltonian Monte Carlo for Extrinsic Posterior Sampling}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.7}Hamiltonian Monte Carlo for Extrinsic Posterior Sampling}{7}}
\citation{neal2011mcmc}
\newlabel{hamiltonian}{{6}{8}}
\newlabel{leap-frog}{{7}{8}}
\citation{neal2011mcmc}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Sampling posterior from a von Mises--Fisher distribution on a unit circle, using HMC with extrinc prior under $\lambda =10^3,10^4,10^5$. Row $1$ shows the posterior distribution of the constraint relaxation $|\theta '\theta -1|$; Row $2$ shows the path of $100$ leap-frog steps; Row $3$ shows the autocorrelation plot (ACF). Large $\lambda $ gives very small constraint relaxation, but suffers from slow mixing due to inefficient local update; smaller $\lambda $ increases the relaxation but results in excellent mixing.\relax }}{10}}
\newlabel{unit_circle}{{2}{10}}
\citation{livingstone2016geometric}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.8}Soft and Hard Constraints}{11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.9}Correcting Projection for Hard Constraint}{11}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Theory}{12}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Examples and Application}{12}}
\citation{jasra2005markov}
\citation{diebolt1994estimation}
\citation{stephens2000dealing}
\newlabel{canonical_dp_prior}{{9}{13}}
\newlabel{ordered_dp_prior}{{10}{13}}
\citation{diebolt1994estimation}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Contour of the posterior density of component means and traceplot of the posterior sample for the component weights, in a 3-component normal mixture model. Panel (a) shows that there is significant overlap among component means, creating label-switching issues in both Gibbs sampling (b) and HMC sampling using canonical prior (c). The ordered Dirichlet prior, estimated under extrinsic prior and correcting projection, significantly reducing label-switching (d).\relax }}{14}}
\newlabel{dirichlet}{{3}{14}}
\bibdata{reference}
\bibcite{boyd2004convex}{{1}{2004}{{Boyd and Vandenberghe}}{{Boyd and Vandenberghe}}}
\bibcite{byrne2013geodesic}{{2}{2013}{{Byrne and Girolami}}{{Byrne and Girolami}}}
\bibcite{diebolt1994estimation}{{3}{1994}{{Diebolt and Robert}}{{Diebolt and Robert}}}
\bibcite{gelfand1992bayesian}{{4}{1992}{{Gelfand et~al.}}{{Gelfand, Smith, and Lee}}}
\bibcite{girolami2011riemann}{{5}{2011}{{Girolami and Calderhead}}{{Girolami and Calderhead}}}
\bibcite{hoff2009simulation}{{6}{2009}{{Hoff}}{{Hoff}}}
\bibcite{hoffman2014no}{{7}{2014}{{Hoffman and Gelman}}{{Hoffman and Gelman}}}
\bibcite{jasra2005markov}{{8}{2005}{{Jasra et~al.}}{{Jasra, Holmes, and Stephens}}}
\bibcite{khatri1977mises}{{9}{1977}{{Khatri and Mardia}}{{Khatri and Mardia}}}
\bibcite{lin2014monogp}{{10}{2014}{{Lin and Dunson}}{{Lin and Dunson}}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Discussion}{15}}
\bibcite{lin2016extrinsic}{{11}{2016}{{Lin et~al.}}{{Lin, St~Thomas, Zhu, and Dunson}}}
\bibcite{livingstone2016geometric}{{12}{2016}{{Livingstone et~al.}}{{Livingstone, Betancourt, Byrne, and Girolami}}}
\bibcite{neal2011mcmc}{{13}{2011}{{Neal}}{{Neal}}}
\bibcite{pakman2014exact}{{14}{2014}{{Pakman and Paninski}}{{Pakman and Paninski}}}
\bibcite{stephens2000dealing}{{15}{2000}{{Stephens}}{{Stephens}}}
\bibcite{zhang2012continuous}{{16}{2012}{{Zhang et~al.}}{{Zhang, Ghahramani, Storkey, and Sutton}}}
\bibstyle{chicago}
