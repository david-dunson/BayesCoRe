if(covariates$GENOTYPE[i]>=1){
AdjacencyListPick[[length(AdjacencyListPick)+1]] = AdjacencyList[[i]]
}
}
GENOTYPEPick = covariates$GENOTYPE[covariates$GENOTYPE>=1]
SEXPick = covariates$GENDER[covariates$GENOTYPE>=1]
m = length(GENOTYPEPick)
ase <- function(A, dim){
if(nrow(A) >= 400){
require(irlba)
A.svd <- irlba(A, nu = dim, nv = dim)
A.svd.values <- A.svd$d[1:dim]
A.svd.vectors <- A.svd$v[,1:dim]
if(dim == 1)
A.coords <- sqrt(A.svd.values) * A.svd.vectors
else
A.coords <- A.svd.vectors %*% diag(sqrt(A.svd.values))
} else{
A.svd <- svd(A)
if(dim == 1)
A.coords <- A.svd$v[,1] * sqrt(A.svd$d[1])
else
A.coords <- A.svd$v[,1:dim] %*% diag(sqrt(A.svd$d[1:dim]))
}
return(list(Xhat=A.coords,scree=A.svd))
}
#
# Alist.log <- lapply(AdjacencyListPick, function(x) log(x + t(x)+1))
# Alist.da <- lapply(Alist.log, function(y) y + diag(x=rowSums(y))/(n-1))
#
# i=1
#
# dhat <- 2
# Tmat <- normT <- matrix(0,m,m)
# pcol1 <- rep(c(1,3),each=n/2)
# pcol2 <- rep(c(2,4),each=n/2)
#
#
# require(Matrix)
# nm = n*m
# # omniA = sparseMatrix(i=1,j=1,x=0, dims=c(nm,nm))
#
# omniA = matrix(0, nm,nm)
# for(i in 1:m) {
#     for(j in 1:i) {
#         Ad <- as.matrix((Alist.da[[i]] + Alist.da[[j]]) / 2)
#         i_idx1 =  n* (i-1)+1
#         i_idx2 = (n* i)
#         j_idx1 =  n* (j-1)+1
#         j_idx2 = (n* j)
#         omniA[i_idx1: i_idx2,j_idx1: j_idx2] = Ad
#         omniA[j_idx1: j_idx2,i_idx1: i_idx2] = t(Ad)
#     }
#   print(i)
# }
#
# dmax <- 2
# Xhat.out <- ase(omniA,dmax)
#
# save(Xhat.out,file ="omni_embedding.Rda")
load(file ="omni_embedding.Rda")
require("ggplot2")
Xhat = Xhat.out$Xhat
df = data.frame( "x1"=Xhat[,1] ,"x2"=Xhat[,2], "id"= as.factor(rep(c(1:m),each=n)),"genotype"= as.factor(rep(GENOTYPEPick,each=n)),"sex"=as.factor(rep(SEXPick,each=n)))
ggplot(df, aes(x=x1, y=x2,col=genotype, group=id)) +  geom_point()
ggplot(df, aes(x=x1, y=x2,col=sex, group=id)) +  geom_point()
Xhat = Xhat.out$Xhat
df0 = data.frame( "x1"=Xhat[,1] ,"x2"=Xhat[,2], "id"= as.factor(rep(c(1:m),each=n)),"genotype"= as.factor(rep(GENOTYPEPick,each=n)),"sex"=as.factor(rep(SEXPick,each=n)), "vertex"= (rep(c(1:n),m)))
df0$genotype.m.x1 = 0
df0$genotype.m.x2 = 0
df0$sex.m.x1 = 0
df0$sex.m.x2 = 0
for(i in 1:n){
for(j in 1:2){
pick = (df0$vertex==i) & (df0$genotype==j)
df0$genotype.m.x1[pick] = median(df0$x1[pick])
df0$genotype.m.x2[pick] = median(df0$x2[pick])
pick = (df0$vertex==i) & (df0$sex==j)
df0$sex.m.x1[pick] = median(df0$x1[pick])
df0$sex.m.x2[pick] = median(df0$x2[pick])
}
}
tot_i = ceiling(n/10)
require("MASS")
getDecisionBoundary<- function(fit, x1){
mu1 = fit$means[1,]
mu2 = fit$means[2,]
sigma = 1/fit$scaling^2
p1 = fit$prior[1]
p2 = fit$prior[2]
a0 = log(p1/p2) - 0.5* sum((mu1+mu2)*(mu1-mu2)/sigma)
a12 = (mu1-mu2)/sigma
decisionY = (-a0 - a12[1]* X[pick,1])/a12[2]
decisionY
}
X= cbind(df0$x1,df0$x2)
df0$decisionX2genotype = 0
df0$decisionX2sex = 0
trim<- function(x,y){
# x[x>(max(y)+0.1)]<-NA
# x[x<(min(y)-0.1)]<-NA
x
}
lda_error = matrix(0, n, 2)
for(i in 1:n){
pick = df0$vertex==i
geno_fit = lda(X[pick,], df$genotype[pick])
geno_error = sum(predict(geno_fit)$class != df$genotype[pick]) / sum(pick)
df0$decisionX2genotype[pick] = trim(getDecisionBoundary(geno_fit, df0$x1[pick]), df0$x2[pick])
sex_fit = lda(X[pick,], df$sex[pick])
sex_error = sum(predict(sex_fit)$class != df$sex[pick]) / sum(pick)
df0$decisionX2sex[pick] = trim(getDecisionBoundary(sex_fit, df0$x1[pick])                                   , df0$x2[pick])
lda_error[i,] = c(geno_error,sex_error)
}
lda_vertex= data.frame("vertex" = c(1:n), "genotype_error" = lda_error[,1], "sex_error" = lda_error[,2])
# genotype.lda.rank = rank(lda_vertex$genotype_error, ties.method = "first")
# sex.lda.rank = rank(lda_vertex$sex_error, ties.method = "first")
# df0$genotype.lda.rank = rep(genotype.lda.rank, m)
# df0$sex.lda.rank = rep(sex.lda.rank, m)
df0$decisionX2genotype
omni_lda = df0
save(omni_lda,"omni_lda.RDa")
save(omni_lda,file="omni_lda.RDa")
load(file ="omni_lda.RDa")
pick = omni_lda$vertex == 1
df = omni_lda[pick,]
print(ggplot(df) +  geom_point(aes(x=x1, y=x2,col=genotype, group=id)) +
# geom_point(aes(x=genotype.m.x1, y=genotype.m.x2,shape=genotype),alpha=0.5) +
geom_line(aes(x=x1, y=decisionX2genotype), linetype=2) +
facet_wrap(~vertex, ncol=5,scales="free"))
pick = omni_lda$vertex == 2
df = omni_lda[pick,]
print(ggplot(df) +  geom_point(aes(x=x1, y=x2,col=genotype, group=id)) +
# geom_point(aes(x=genotype.m.x1, y=genotype.m.x2,shape=genotype),alpha=0.5) +
geom_line(aes(x=x1, y=decisionX2genotype), linetype=2) +
facet_wrap(~vertex, ncol=5,scales="free"))
pick = omni_lda$vertex == 111
df = omni_lda[pick,]
print(ggplot(df) +  geom_point(aes(x=x1, y=x2,col=genotype, group=id)) +
# geom_point(aes(x=genotype.m.x1, y=genotype.m.x2,shape=genotype),alpha=0.5) +
geom_line(aes(x=x1, y=decisionX2genotype), linetype=2) +
facet_wrap(~vertex, ncol=5,scales="free"))
plotOmni(idx){
plotOmni<- function(idx){
pick = omni_lda$vertex %in% idx
df = omni_lda[pick,]
print(ggplot(df) +  geom_point(aes(x=x1, y=x2,col=genotype, group=id)) +
geom_line(aes(x=x1, y=decisionX2genotype), linetype=2) +
facet_wrap(~vertex, ncol=5,scales="free"))
}
pick2
list_regions<- c(63,52,60,62,164,166, 121,123,74,158,92,93,94,95,96)
list_regions + n
n/2
list_regions = c(list_regions, list_regions + n/2)
list_regions<- c(63,52,60,62,164,166, 121,123,74,158,92,93,94,95,96)
list_regions = c(list_regions, list_regions + n/2)
plotOmni(list_regions)
load(file ="omni_lda.RDa")
plotOmni<- function(idx){
pick = omni_lda$vertex %in% idx
df = omni_lda[pick,]
df$vertex = factor(df$vertex, levels=idx)
print(ggplot(df) +  geom_point(aes(x=x1, y=x2,col=genotype, group=id)) +
geom_line(aes(x=x1, y=decisionX2genotype), linetype=2) +
facet_wrap(~vertex, ncol=5,scales="free"))
}
list_regions<- c(63,52,60,62,164,166, 121,123,74,158,92,93,94,95,96)
list_regions = c(list_regions, list_regions + n/2)
plotOmni(list_regions)
list_regions<- c(63,52,60,62,164,166, 121,123,74,158,92,93,94,95,96)
list_regions = c(list_regions)
plotOmni(list_regions)
lda_vertex$genotype_error
lda_vertex$genotype_error[list_regions]
lda_vertex$genotype_error[c(60,62,164,166)]
plotOmni(list_regions)
list_regions<- c(63,52,60,62,164,166, 121,123,74,158,92,93,94,95,96)
list_regions = c(list_regions)
lda_vertex$genotype_error[c(60,62,164,166)]
plotOmni(c(60,62,164,166))
load(file ="omni_lda.RDa")
plotOmni<- function(idx){
pick = omni_lda$vertex %in% idx
df = omni_lda[pick,]
df$vertex = factor(df$vertex, levels=idx)
print(ggplot(df) +  geom_point(aes(x=x1, y=x2,col=genotype, group=id)) +
# geom_line(aes(x=x1, y=decisionX2genotype), linetype=2) +
facet_wrap(~vertex, ncol=5,scales="free"))
}
list_regions<- c(63,52,60,62,164,166, 121,123,74,158,92,93,94,95,96)
list_regions = c(list_regions)
lda_vertex$genotype_error[c(60,62,164,166)]
plotOmni(c(60,62,164,166))
lda_vertex$genotype_error
save(lda_vertex,file="lda_vertex_error.RDa")
load("lda_vertex_error.RDa")
list_regions<- c(63,52,60,62,164,166, 121,123,74,158,92,93,94,95,96)
list_regions = c(list_regions)
plotOmni(c(60,62,164,166))
load("lda_vertex_error.RDa")
print(lda_vertex$genotype_error)
print(lda_vertex$genotype_error[c(60,62,164,166)])
list_regions<- c(63,52,60,62,164,166, 121,123,74,158,92,93,94,95,96)
list_regions = c(list_regions)
plotOmni(c(60,62,164,166))
load("lda_vertex_error.RDa")
print(lda_vertex$genotype_error[c(60,62,164,166)])
list_regions<- c(63,52,60,62,164,166, 121,123,74,158,92,93,94,95,96)
list_regions = c(list_regions)
plotOmni(c(60,62,164,166)+ n/2)
load("lda_vertex_error.RDa")
print(lda_vertex$genotype_error[c(60,62,164,166)+ n/2])
list_regions<- c(63,52,60,62,164,166, 121,123,74,158,92,93,94,95,96)
list_regions = c(list_regions)
plotOmni(c(60,62,164,166)+ n/2)
load("lda_vertex_error.RDa")
print(lda_vertex$genotype_error[c(60,62,164,166)+ n/2])
rstan:::rstudio_stanc("git/constrainedBayes/gplvm/gplvm.stan")
rstan:::rstudio_stanc("git/constrainedBayes/gplvm/gplvm.stan")
rstan:::rstudio_stanc("git/constrainedBayes/gplvm/gplvm.stan")
rstan:::rstudio_stanc("git/constrainedBayes/gplvm/gplvm.stan")
rstan:::rstudio_stanc("git/constrainedBayes/gplvm/gplvm.stan")
rstan:::rstudio_stanc("git/constrainedBayes/gplvm/gplvm.stan")
rstan:::rstudio_stanc("git/constrainedBayes/gplvm/gplvm.stan")
rstan:::rstudio_stanc("git/constrainedBayes/gplvm/gplvm.stan")
rstan:::rstudio_stanc("git/constrainedBayes/gplvm/gplvm.stan")
rstan:::rstudio_stanc("git/constrainedBayes/gplvm/gplvm.stan")
rstan:::rstudio_stanc("git/constrainedBayes/gplvm/gplvm.stan")
rstan:::rstudio_stanc("git/constrainedBayes/gplvm/gplvm.stan")
rstan:::rstudio_stanc("git/constrainedBayes/gplvm/gplvm.stan")
rstan:::rstudio_stanc("git/constrainedBayes/gplvm/gplvm.stan")
rstan:::rstudio_stanc("git/constrainedBayes/gplvm/gplvm.stan")
rstan:::rstudio_stanc("git/constrainedBayes/gplvm/gplvm.stan")
rstan:::rstudio_stanc("git/constrainedBayes/gplvm/gplvm.stan")
rstan:::rstudio_stanc("git/constrainedBayes/gplvm/gplvm.stan")
rstan:::rstudio_stanc("git/constrainedBayes/gplvm/gplvm.stan")
rstan:::rstudio_stanc("git/constrainedBayes/gplvm/gplvm.stan")
options(max.print=100)
setwd("~/git/empiricalTensor/gplvm/")
require("rstan")
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
#################################################
r = 30
w = seq(0,20,length.out = r)
n = 100
p = 1
x<- runif(n)
x[1] = 0.001
spec<- function(rho, phi){
phi*exp(-1/4 * rho^2 * w^2)
}
g = spec(0.1,10)
min(g)
alpha<- matrix(rnorm(r*p),r) * sqrt(g)
beta<- matrix(rnorm(r*p),r) * sqrt(g)
theta<- rbind(alpha, beta)
Sigma = rep(0.1,p)
xw =outer(x,w,"*")
X = cbind(cos(xw),sin(xw))
y = X%*%theta + matrix(rnorm(n*p),n)%*%diag(Sigma^0.5,1)
plot(x,y[,1])
# plot(x,y[,2])
# plot(x,y[,3])
#######################################################
ss_model = stan_model(file= "gplvm.stan")
ss_model = stan_model(file= "gplvm.stan")
setwd("~/git/empiricalTensor/hmc_constraint/Network")
require("rstan")
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
#######################################################
extractPosterior<-function(varname, dimen, stan_fit){
if(dimen==1){
eval(parse(text=paste(stan_fit,"@sim$samples[[1]]$`",varname,"`",sep="")))
}else{
sapply(c(1:dimen), function(i)  eval(parse(text=paste(stan_fit,"@sim$samples[[1]]$`",varname,"[",i, "]`",sep=""))))
}
}
extractPosteriorMat<-function(varname, d1,d2, stan_fit){
L = lapply(c(1:d2), function(j){
sapply(c(1:d1), function(i)  eval(parse(text=paste(stan_fit,"@sim$samples[[1]]$`",varname,"[",i,",",j, "]`",sep=""))))
})
do.call("cbind",L)
}
extractPosterior3D<-function(varname, d1,d2,d3, stan_fit){
n = length( eval(parse(text=paste(stan_fit,"@sim$samples[[1]]$`",varname,"[",1,",",1,",",1, "]`",sep=""))))
L = matrix(0, n, d1*d2*d3)
for(i in 1:d1){
for(j in 1:d2){
for(l in 1:d3){
idx = (i-1)*d2*d3 + (j-1)*d3+ l;
L[,idx] = eval(parse(text=paste(stan_fit,"@sim$samples[[1]]$`",varname,"[",i,",",j,",",l, "]`",sep="")))
}
}
}
L
}
setwd("~/git/constrainedBayes/hmc_constraint/Network")
require("rstan")
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
#######################################################
extractPosterior<-function(varname, dimen, stan_fit){
if(dimen==1){
eval(parse(text=paste(stan_fit,"@sim$samples[[1]]$`",varname,"`",sep="")))
}else{
sapply(c(1:dimen), function(i)  eval(parse(text=paste(stan_fit,"@sim$samples[[1]]$`",varname,"[",i, "]`",sep=""))))
}
}
extractPosteriorMat<-function(varname, d1,d2, stan_fit){
L = lapply(c(1:d2), function(j){
sapply(c(1:d1), function(i)  eval(parse(text=paste(stan_fit,"@sim$samples[[1]]$`",varname,"[",i,",",j, "]`",sep=""))))
})
do.call("cbind",L)
}
extractPosterior3D<-function(varname, d1,d2,d3, stan_fit){
n = length( eval(parse(text=paste(stan_fit,"@sim$samples[[1]]$`",varname,"[",1,",",1,",",1, "]`",sep=""))))
L = matrix(0, n, d1*d2*d3)
for(i in 1:d1){
for(j in 1:d2){
for(l in 1:d3){
idx = (i-1)*d2*d3 + (j-1)*d3+ l;
L[,idx] = eval(parse(text=paste(stan_fit,"@sim$samples[[1]]$`",varname,"[",i,",",j,",",l, "]`",sep="")))
}
}
}
L
}
ss_model = stan_model(file= "ortho_tensor.stan")
N = 70
d1 = 2
d2 = 3
p = 5
U = matrix(rnorm(N*d1),N,d1)
U = qr.Q(qr(U))
y = array(0, c(N,N,p))
for(l in 1:p){
eta = rnorm(d1)
UDU = U%*%diag(eta)%*%t(U)
p_mat = 1/(1+exp(-UDU))
y_l = (matrix(runif(N*N),N)<p_mat)*1
Lower=lower.tri(y_l)
y_l[Lower] = t(y_l)[Lower]
y[,,l] = y_l
}
lambda1=0   # ordering in tau
lambda2=1E3  # orthonormality
lambda3=1E3  # positive
input_dat <- list(N=N, p=p,d1=d1,d2=d2 , y=y,lambda1 = lambda1, lambda2 = lambda2,lambda3= lambda3)
n_steps = 1E4
ss_fit <- sampling(ss_model, data = input_dat, iter = n_steps, chains = 1, algorithm = "NUTS")
N = 10
d1 = 2
d2 = 3
p = 5
U = matrix(rnorm(N*d1),N,d1)
U = qr.Q(qr(U))
y = array(0, c(N,N,p))
for(l in 1:p){
eta = rnorm(d1)
UDU = U%*%diag(eta)%*%t(U)
p_mat = 1/(1+exp(-UDU))
y_l = (matrix(runif(N*N),N)<p_mat)*1
Lower=lower.tri(y_l)
y_l[Lower] = t(y_l)[Lower]
y[,,l] = y_l
}
lambda1=0   # ordering in tau
lambda2=1E3  # orthonormality
lambda3=1E3  # positive
input_dat <- list(N=N, p=p,d1=d1,d2=d2 , y=y,lambda1 = lambda1, lambda2 = lambda2,lambda3= lambda3)
n_steps = 1E4
ss_fit <- sampling(ss_model, data = input_dat, iter = n_steps, chains = 1, algorithm = "NUTS")
sampling_idx<- c((n_steps/2+1):n_steps)
post_U = extractPosteriorMat("U",N,d1,"ss_fit")
acf(post_U[sampling_idx,1])
acf(post_U[sampling_idx,N+1])
ts.plot(post_U[sampling_idx,1])
ts.plot(post_U[sampling_idx,N+2])
post_V = extractPosteriorMat("V",p,d2,"ss_fit")
acf(post_V[sampling_idx,1])
acf(post_V[sampling_idx,N+1])
N = 70
d1 = 2
d2 = 3
p = 5
U = matrix(rnorm(N*d1),N,d1)
U = qr.Q(qr(U))
y = array(0, c(N,N,p))
for(l in 1:p){
eta = rnorm(d1)
UDU = U%*%diag(eta)%*%t(U)
p_mat = 1/(1+exp(-UDU))
y_l = (matrix(runif(N*N),N)<p_mat)*1
Lower=lower.tri(y_l)
y_l[Lower] = t(y_l)[Lower]
y[,,l] = y_l
}
lambda1=0   # ordering in tau
lambda2=1E3  # orthonormality
lambda3=1E3  # positive
input_dat <- list(N=N, p=p,d1=d1,d2=d2 , y=y,lambda1 = lambda1, lambda2 = lambda2,lambda3= lambda3)
n_steps = 1E4
ss_fit <- sampling(ss_model, data = input_dat, iter = n_steps, chains = 1, algorithm = "NUTS")
N = 10
d1 = 2
d2 = 3
p = 5
U = matrix(rnorm(N*d1),N,d1)
U = qr.Q(qr(U))
y = array(0, c(N,N,p))
for(l in 1:p){
eta = rnorm(d1)
UDU = U%*%diag(eta)%*%t(U)
p_mat = 1/(1+exp(-UDU))
y_l = (matrix(runif(N*N),N)<p_mat)*1
Lower=lower.tri(y_l)
y_l[Lower] = t(y_l)[Lower]
y[,,l] = y_l
}
lambda1=0   # ordering in tau
lambda2=1E3  # orthonormality
lambda3=1E3  # positive
post_U = extractPosteriorMat("U",N,d1,"ss_fit")
acf(post_U[sampling_idx,1])
acf(post_U[sampling_idx,N+1])
ts.plot(post_U[sampling_idx,1])
ts.plot(post_U[sampling_idx,N+2])
post_V = extractPosteriorMat("V",p,d2,"ss_fit")
acf(post_V[sampling_idx,1])
acf(post_V[sampling_idx,N+1])
ts.plot(post_V[sampling_idx,1])
ts.plot(post_V[sampling_idx,N+2])
post_eta = extractPosterior3D("eta",d1,d1,d2,"ss_fit")
ts.plot(post_eta[sampling_idx,1])
acf(post_eta[sampling_idx,2])
U1 = matrix(0,N,d)
for(j in 1:d){
U1[,j]=post_U[n_steps/2,((j-1)*N+1):(j*N)]
}
t(U1)%*%U1
t(U1)%*%U1
U1
U1 = matrix(0,N,d)
U1
print(U1)
U1
save(ss_fit,file="network1.RDa")
setwd("~/git/constrainedBayes/hmc_constraint/Network")
dotR <- file.path(Sys.getenv("HOME"), ".R")
if (!file.exists(dotR)) dir.create(dotR)
M <- file.path(dotR, "Makevars")
if (!file.exists(M)) file.create(M)
cat("\nCXXFLAGS=-O3 -mtune=native -march=native -Wno-unused-variable -Wno-unused-function",
file = M, sep = "\n", append = TRUE)
Sys.setenv(MAKEFLAGS = "-j4")
install.packages("Rcpp")
Sys.setenv(MAKEFLAGS = "-j4")
install.packages("rstan", repos = "https://cloud.r-project.org/", dependencies=TRUE)
require("rstan")
setwd("~/git/constrainedBayes/hmc_constraint/Network")
require("rstan")
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
#######################################################
extractPosterior<-function(varname, dimen, stan_fit){
if(dimen==1){
eval(parse(text=paste(stan_fit,"@sim$samples[[1]]$`",varname,"`",sep="")))
}else{
sapply(c(1:dimen), function(i)  eval(parse(text=paste(stan_fit,"@sim$samples[[1]]$`",varname,"[",i, "]`",sep=""))))
}
}
extractPosteriorMat<-function(varname, d1,d2, stan_fit){
L = lapply(c(1:d2), function(j){
sapply(c(1:d1), function(i)  eval(parse(text=paste(stan_fit,"@sim$samples[[1]]$`",varname,"[",i,",",j, "]`",sep=""))))
})
do.call("cbind",L)
}
extractPosterior3D<-function(varname, d1,d2,d3, stan_fit){
n = length( eval(parse(text=paste(stan_fit,"@sim$samples[[1]]$`",varname,"[",1,",",1,",",1, "]`",sep=""))))
L = matrix(0, n, d1*d2*d3)
for(i in 1:d1){
for(j in 1:d2){
for(l in 1:d3){
idx = (i-1)*d2*d3 + (j-1)*d3+ l;
L[,idx] = eval(parse(text=paste(stan_fit,"@sim$samples[[1]]$`",varname,"[",i,",",j,",",l, "]`",sep="")))
}
}
}
L
}
ss_model = stan_model(file= "ortho_tensor.stan")
load("tensorA.RDa")
y=A
N = length(A[,1,1])
N
dims(A)
dim(A)
N = dim(A)[1]
p = dim(A)[3]
N
p
d1 = 10
d2 = 10
lambda1=0   # ordering in tau
lambda2=1E3  # orthonormality
lambda3=1E3  # positive
input_dat <- list(N=N, p=p,d1=d1,d2=d2 , y=y,lambda1 = lambda1, lambda2 = lambda2,lambda3= lambda3)
n_steps = 1E4
ss_fit <- sampling(ss_model, data = input_dat, iter = n_steps, chains = 1, algorithm = "NUTS")
